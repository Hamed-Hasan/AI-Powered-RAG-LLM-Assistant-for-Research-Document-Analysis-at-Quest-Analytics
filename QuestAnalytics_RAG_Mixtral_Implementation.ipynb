{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AI-Powered RAG Assistant Using Mixtral-8x7B LLM for Research Document Analysis at Quest Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 1000 characters of the document:\n",
      "A Comprehensive Review of Low-Rank\n",
      "Adaptation in Large Language Models for\n",
      "Efficient Parameter Tuning\n",
      "September 10, 2024\n",
      "Abstract\n",
      "Natural Language Processing (NLP) often involves pre-training large\n",
      "models on extensive datasets and then adapting them for specific tasks\n",
      "through fine-tuning. However, as these models grow larger, like GPT-3\n",
      "with 175 billion parameters, fully fine-tuning them becomes computa-\n",
      "tionally expensive. We propose a novel method called LoRA (Low-Rank\n",
      "Adaptation) that significantly reduces the overhead by freezing the orig-\n",
      "inal model weights and only training small rank decomposition matrices.\n",
      "This leads to up to 10,000 times fewer trainable parameters and reduces\n",
      "GPU memory usage by three times. LoRA not only maintains but some-\n",
      "times surpasses fine-tuning performance on models like RoBERTa, De-\n",
      "BERTa, GPT-2, and GPT-3. Unlike other methods, LoRA introduces\n",
      "no extra latency during inference, making it more efficient for practical\n",
      "applications. All relevant code an\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the PDF document\n",
    "def load_pdf_document(pdf_path):\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pages = loader.load()\n",
    "    \n",
    "    # Display first 1000 characters\n",
    "    content = \"\"\n",
    "    for page in pages:\n",
    "        content += page.page_content\n",
    "    \n",
    "    print(\"First 1000 characters of the document:\")\n",
    "    print(content[:1000])\n",
    "    return pages\n",
    "\n",
    "# Usage example\n",
    "pdf_path = \"A_Comprehensive_Review_of_Low_Rank_Adaptation_in_Large_Language_Models_for_Efficient_Parameter_Tuning-1.pdf\"\n",
    "documents = load_pdf_document(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
